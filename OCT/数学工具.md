# 算法

## RANSAC算法

RANSAC, RANdom SAmple Consensus. 随机抽样一致算法。

**一、解决的问题**

当一组样本数据中含有（较小波动的）正常数据（inliers）和（较大波动的）异常数据（outliers），且异常数据的量还不小于正常数据的量，此时用最小二乘法将难以获得期望的曲线（即能拟合正常数据的直线），RANSAC算法就可以用来代替最小二乘法算出期望的直线参数（实际上RANSAC算法适用于任何模型，为了简单这里以直线模型为例）。

一句话概括：一种从一组包括噪声的观测数据中通过迭代的方法预计出数据所满足的某个数学模型的参数的方法（你需要首先自己选择一个数学模型，例如线性模型，然后通过该算法迭代出参数）。

**二、算法描述**

符号解释：
- $S$，样本点集。
- $M$，数学模型（假设为 $y=ax+b$）。
- $N$，计算模型 $M$ 的参数所需的最少点数。
- $K$，算法迭代次数。
- $T$，判断一点是否适用于模型 $M$ 的阈值误差。
- $D$，判断模型 $M$ 是否适用于样本点集 $S$ 的最小样本数。

算法流程：
1. 从样本点集 $S$ 中随机抽取一个子样本$P$（$P$所含点数不小于$N$）来计算模型$M$的参数。
2. 将余集 $S^{*}=S-P$ 中的每个点代入模型 $M$，若所得误差小于设定阈值 $T$ 则将此点加入$P$，否则抛弃。
3. 若 $P$ 中点的数量小于设定值 $D$ 则抛弃模型 $M$，否则用最小二乘法和点集 $P$ 重新新计算模型 $M'$ 和点集 $P$ 的误差 $E$。
4. 将 $1-3$ 迭代 $K$ 次，每次产生的新模型 $M'$ 仅当 $P$ 中的点的数量大于 $D$ 且误差 $E$ 比当前模型 $M$ 的误差 $E$ 小时才替换当前模型，否则抛弃。


注： $N$ 和 $D$ 的作用是不同的，前者使用较少的点来先算出一个模型，然后判断多个点适合这个模型，而后者是想要获取模型的用户能接受的最低下限。


**三、优化策略**




## ICP算法

ICP, Iterative Closest Point. 迭代最近点算法。

**一、解决的问题**






## Sparse Representation算法

Sparse Representation. 稀疏表示算法。




# 距离

曼哈顿距离（Manhattan Distance, MD）


欧几里德距离（Euclidean Distance, ED）


切比雪夫距离（）


切线距离（Tangent Distance, TD）



